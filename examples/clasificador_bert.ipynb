{
 "cells": [
  {
   "cell_type": "code",
   "id": "30c5340a-2c05-470d-b322-a43bcfcb6b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T16:30:45.730375Z",
     "start_time": "2025-11-04T16:30:27.499437Z"
    }
   },
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f8e703-8dda-4804-aee2-c62b5680371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH = os.getcwd()\n",
    "DIR_DATA = PATH + '{0}data{0}'.format(os.sep)\n",
    "sys.path.append(PATH) if PATH not in list(sys.path) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285a569e-1a98-428c-93a7-b42f08a5287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4c40a-1f00-4dcf-b83e-cc69ae744bfd",
   "metadata": {},
   "source": [
    "# Paso 1: ImportaciÃ³n de librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1323b803-62eb-4b8a-8c57-ca337767b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\epuerta\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff97c9-bb7e-44e8-9e56-1355a711786d",
   "metadata": {},
   "source": [
    "# Paso 2: Carga y limpieza del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28011bb3-43a9-41d3-8bcb-90979c2475f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DIR_DATA + \"dataset_sentimientos_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767d6609-b5d8-479b-b902-04d667ce19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce302ff-4dfd-44ca-b4c8-b112d540359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ReseÃ±a', 'Sentimiento']].dropna()\n",
    "df['Sentimiento'] = df['Sentimiento'].map({'Positiva': 1, 'Negativa': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d156a2-4dd0-404e-9e4d-f772b4c460d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReseÃ±a</th>\n",
       "      <th>Sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estoy feliz con mi compra, funciona perfecto.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estoy feliz con mi compra, funciona perfecto.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recomiendo este servicio sin dudarlo.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muy recomendable, volverÃ© a comprar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy recomendable, volverÃ© a comprar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Muy recomendable, volverÃ© a comprar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>No funciona como se esperaba.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Buen precio y envÃ­o rÃ¡pido.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Buen precio y envÃ­o rÃ¡pido.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Una experiencia fantÃ¡stica de principio a fin.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ReseÃ±a  Sentimiento\n",
       "0     Estoy feliz con mi compra, funciona perfecto.            1\n",
       "1     Estoy feliz con mi compra, funciona perfecto.            1\n",
       "2             Recomiendo este servicio sin dudarlo.            1\n",
       "3              Muy recomendable, volverÃ© a comprar.            1\n",
       "4              Muy recomendable, volverÃ© a comprar.            1\n",
       "..                                              ...          ...\n",
       "495            Muy recomendable, volverÃ© a comprar.            1\n",
       "496                   No funciona como se esperaba.            0\n",
       "497                     Buen precio y envÃ­o rÃ¡pido.            1\n",
       "498                     Buen precio y envÃ­o rÃ¡pido.            1\n",
       "499  Una experiencia fantÃ¡stica de principio a fin.            1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1864d59-6a44-472a-9f0d-f2ab0b54a8a2",
   "metadata": {},
   "source": [
    "# Paso 3: SeparaciÃ³n en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6083b673-7e7a-4729-b9c7-73c59a8e2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "df['ReseÃ±a'].tolist(), df['Sentimiento'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911ba49-d631-41dc-9a98-2ce4c36b62f2",
   "metadata": {},
   "source": [
    "# Paso 4: TokenizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40abd1b6-49cd-4bd0-a2e7-ebe4ab210c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128) \n",
    "\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f4b8b-6ee9-4d15-aefd-11ad5b10dc15",
   "metadata": {},
   "source": [
    "# Paso 5: CreaciÃ³n de los datasets formales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff27fde1-ff12-48c5-b234-201aa1319e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({ \n",
    "\n",
    "    'input_ids': train_encodings['input_ids'], \n",
    "\n",
    "    'attention_mask': train_encodings['attention_mask'], \n",
    "\n",
    "    'labels': train_labels \n",
    "\n",
    "}) \n",
    "\n",
    "test_dataset = Dataset.from_dict({ \n",
    "\n",
    "    'input_ids': test_encodings['input_ids'], \n",
    "\n",
    "    'attention_mask': test_encodings['attention_mask'], \n",
    "\n",
    "    'labels': test_labels \n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a9c79-5878-4ed3-93b5-277da2bcc684",
   "metadata": {},
   "source": [
    "# Paso 6: DefiniciÃ³n de mÃ©tricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bd84d2-86ff-4f47-bad6-c9859aa360f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred): \n",
    "\n",
    "    logits, labels = eval_pred \n",
    "\n",
    "    preds = np.argmax(logits, axis=-1) \n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary') \n",
    "\n",
    "    acc = accuracy_score(labels, preds) \n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350e325-a8d5-48a3-a3a4-4fd8270b9ef6",
   "metadata": {},
   "source": [
    "# Paso 7: Carga del modelo preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ffae2d2-4ce7-4f6b-9096-987b9b070343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45815ef3-17a4-466a-9be0-ab17ecf447b6",
   "metadata": {},
   "source": [
    "# Paso 8: ConfiguraciÃ³n del entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b77faf6-681c-4e2d-af82-993196fdc81d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m Training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m      2\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      3\u001B[0m     logging_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      4\u001B[0m     logging_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[0;32m      5\u001B[0m     per_device_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[0;32m      6\u001B[0m     per_device_eval_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[0;32m      7\u001B[0m     num_train_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m      8\u001B[0m     save_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[0;32m      9\u001B[0m     save_total_limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     10\u001B[0m     load_best_model_at_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     11\u001B[0m     metric_for_best_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     12\u001B[0m     greater_is_better\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     13\u001B[0m     evaluation_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# ðŸ‘ˆ evaluar al final de cada Ã©poca\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     save_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msteps\u001B[39m\u001B[38;5;124m\"\u001B[39m,         \u001B[38;5;66;03m# ðŸ‘ˆ guardar al final de cada Ã©poca\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     report_to\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m               \u001B[38;5;66;03m# ðŸ‘ˆ evita el login de wandb\u001B[39;00m\n\u001B[0;32m     16\u001B[0m )\n",
      "\u001B[1;31mTypeError\u001B[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "Training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    evaluation_strategy=\"steps\",  # ðŸ‘ˆ evaluar al final de cada Ã©poca\n",
    "    save_strategy=\"steps\",         # ðŸ‘ˆ guardar al final de cada Ã©poca\n",
    "    report_to=\"none\"               # ðŸ‘ˆ evita el login de wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b9df5-17fd-4df6-8028-dc88413c712b",
   "metadata": {},
   "source": [
    "# Paso 9: Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a7162-9ed8-48b5-addf-e836334935c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( \n",
    "\n",
    "    model=model, \n",
    "\n",
    "    args=training_args, \n",
    "\n",
    "    train_dataset=train_dataset, \n",
    "\n",
    "    eval_dataset=test_dataset, \n",
    "\n",
    "    compute_metrics=compute_metrics \n",
    "\n",
    ") \n",
    "\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05cee1-e667-44cc-9127-feb88c323221",
   "metadata": {},
   "source": [
    "# Paso 10: EvaluaciÃ³n final del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023e410-255d-4e28-b8ff-452631e84a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate() \n",
    "\n",
    "print(\"Resultados:\", results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4878e7-6a66-490f-b8c1-7cf5e6a5e070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
