{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e301715d-b508-44f1-8f4b-96e0c57488cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\epuerta\\\\OneDrive - Universidad Tecnológica de Bolívar\\\\Apps\\\\courseNLP\\\\examples\\\\data\\\\tass\\\\'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH = os.getcwd()\n",
    "DIR_DATA = PATH + '{0}data{0}tass{0}'.format(os.sep)\n",
    "sys.path.append(PATH) if PATH not in list(sys.path) else None\n",
    "DIR_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375cfc7-8f6d-42a8-bff8-c92f62068856",
   "metadata": {},
   "source": [
    "## 'http://tass.sepln.org/2018/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df52b8f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-21T03:05:35.137355Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder \n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextProcessing\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n",
      "File \u001b[1;32m~\\OneDrive - Universidad Tecnológica de Bolívar\\Apps\\courseNLP\\examples\\logic\\text_processing.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01municodedata\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TweetTokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from logic.text_processing import TextProcessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, log_loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191fa4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: Text Processing\n",
      "es: ['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "tp = TextProcessing()\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b3ebff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment/polarity/value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768213876278165504</td>\n",
       "      <td>OnceBukowski</td>\n",
       "      <td>-Me caes muy bien \\r\\n-Tienes que jugar más pa...</td>\n",
       "      <td>2016-08-23 22:30:35</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768213567418036224</td>\n",
       "      <td>anahorxn</td>\n",
       "      <td>@myendlesshazza a. que puto mal escribo\\r\\n\\r\\...</td>\n",
       "      <td>2016-08-23 22:29:21</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768212591105703936</td>\n",
       "      <td>martitarey13</td>\n",
       "      <td>@estherct209 jajajaja la tuya y la d mucha gen...</td>\n",
       "      <td>2016-08-23 22:25:29</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768221670255493120</td>\n",
       "      <td>endlessmilerr</td>\n",
       "      <td>Quiero mogollón a @AlbaBenito99 pero sobretodo...</td>\n",
       "      <td>2016-08-23 23:01:33</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768221021300264964</td>\n",
       "      <td>JunoWTFL</td>\n",
       "      <td>Vale he visto la tia bebiendose su regla y me ...</td>\n",
       "      <td>2016-08-23 22:58:58</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid           user  \\\n",
       "0  768213876278165504   OnceBukowski   \n",
       "1  768213567418036224       anahorxn   \n",
       "2  768212591105703936   martitarey13   \n",
       "3  768221670255493120  endlessmilerr   \n",
       "4  768221021300264964       JunoWTFL   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  -Me caes muy bien \\r\\n-Tienes que jugar más pa...  2016-08-23 22:30:35   \n",
       "1  @myendlesshazza a. que puto mal escribo\\r\\n\\r\\...  2016-08-23 22:29:21   \n",
       "2  @estherct209 jajajaja la tuya y la d mucha gen...  2016-08-23 22:25:29   \n",
       "3  Quiero mogollón a @AlbaBenito99 pero sobretodo...  2016-08-23 23:01:33   \n",
       "4  Vale he visto la tia bebiendose su regla y me ...  2016-08-23 22:58:58   \n",
       "\n",
       "  lang sentiment/polarity/value  \n",
       "0   es                     NONE  \n",
       "1   es                        N  \n",
       "2   es                        N  \n",
       "3   es                        P  \n",
       "4   es                        N  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(DIR_DATA + 'tass2018_es_train.csv', sep=',')\n",
    "data_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc97fe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment/polarity/value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770976639173951488</td>\n",
       "      <td>noseashetero</td>\n",
       "      <td>@noseashetero 1000/10 de verdad a ti que voy a...</td>\n",
       "      <td>2016-08-31 13:28:49</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771092421866389508</td>\n",
       "      <td>Templelx</td>\n",
       "      <td>@piscolabisaereo @HistoriaNG @SPosteguillo las...</td>\n",
       "      <td>2016-08-31 21:08:54</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>771092111429083136</td>\n",
       "      <td>esskuu94</td>\n",
       "      <td>Al final han sido 3h  Bueno, mañana tengo fies...</td>\n",
       "      <td>2016-08-31 21:07:40</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771092070572449796</td>\n",
       "      <td>__ariadna9</td>\n",
       "      <td>@Jorge_Ruiz14 yo no tengo tiempo para esas cos...</td>\n",
       "      <td>2016-08-31 21:07:30</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771094192508600320</td>\n",
       "      <td>_cristtina15_</td>\n",
       "      <td>@_MissChaotic_ ves ese brillo? es un coso que ...</td>\n",
       "      <td>2016-08-31 21:15:56</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid           user  \\\n",
       "0  770976639173951488   noseashetero   \n",
       "1  771092421866389508       Templelx   \n",
       "2  771092111429083136       esskuu94   \n",
       "3  771092070572449796     __ariadna9   \n",
       "4  771094192508600320  _cristtina15_   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  @noseashetero 1000/10 de verdad a ti que voy a...  2016-08-31 13:28:49   \n",
       "1  @piscolabisaereo @HistoriaNG @SPosteguillo las...  2016-08-31 21:08:54   \n",
       "2  Al final han sido 3h  Bueno, mañana tengo fies...  2016-08-31 21:07:40   \n",
       "3  @Jorge_Ruiz14 yo no tengo tiempo para esas cos...  2016-08-31 21:07:30   \n",
       "4  @_MissChaotic_ ves ese brillo? es un coso que ...  2016-08-31 21:15:56   \n",
       "\n",
       "  lang sentiment/polarity/value  \n",
       "0   es                        P  \n",
       "1   es                        P  \n",
       "2   es                        P  \n",
       "3   es                        N  \n",
       "4   es                        N  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(DIR_DATA + 'tass2018_es_test.csv', sep=',')\n",
    "data_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ace549f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 1008)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = [tp.transformer(row) for row in data_train['content'].tolist()]\n",
    "#y_train = le.fit_transform(data_train['sentiment/polarity/value'])\n",
    "y_train = data_train['sentiment/polarity/value']\n",
    "len(x_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9b7be0-5962-406f-93d9-31b03dab0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9945c0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 506)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [tp.transformer(row) for row in data_test['content'].tolist()]\n",
    "#y_test = le.fit_transform(data_test['sentiment/polarity/value'])\n",
    "y_test = data_test['sentiment/polarity/value']\n",
    "len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b9220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(analyzer='word', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f397be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d8a423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dd8deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = bow.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87edb6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "986c24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample train: [('N', 418), ('NEU', 133), ('NONE', 139), ('P', 318)]\n"
     ]
    }
   ],
   "source": [
    "print('**Sample train:', sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1d3c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample test: [('N', 219), ('NEU', 69), ('NONE', 62), ('P', 156)]\n"
     ]
    }
   ],
   "source": [
    "print('**Sample test:', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0eb45855",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = ShuffleSplit(n_splits=10, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ba65234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_train = RandomOverSampler(random_state=1000)\n",
    "x_train, y_train = ros_train.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66c8010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**OverSample train: [('N', 418), ('NEU', 418), ('NONE', 418), ('P', 418)]\n"
     ]
    }
   ],
   "source": [
    "print('**OverSample train:', sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19b6897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_test = RandomOverSampler(random_state=1000)\n",
    "x_test, y_test = ros_test.fit_resample(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69836dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**OverSample test: [('N', 219), ('NEU', 219), ('NONE', 219), ('P', 219)]\n"
     ]
    }
   ],
   "source": [
    "print('**OverSample test:', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2364f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "246b4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_scores = []\n",
    "recalls_scores = []\n",
    "precisions_scores = []\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a59dfd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in k_fold.split(x_train, y_train):\n",
    "    data_train = x_train[train_index]\n",
    "    target_train = y_train[train_index]\n",
    "    \n",
    "    data_test = x_train[test_index]\n",
    "    target_test = y_train[test_index]\n",
    "\n",
    "    softmax.fit(data_train, target_train)\n",
    "    predict = softmax.predict(data_test)\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(target_test, predict)\n",
    "    accuracies_scores.append(accuracy)\n",
    "    # Recall\n",
    "    recall = recall_score(target_test, predict, average='macro')\n",
    "    recalls_scores.append(recall)\n",
    "    # Precision\n",
    "    precision = precision_score(target_test, predict, average='weighted')\n",
    "    precisions_scores.append(precision)\n",
    "    # F1\n",
    "    f1 = f1_score(target_test, predict, average='weighted')\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddae023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_recall = round(np.mean(recalls_scores) * 100, 2)\n",
    "average_precision = round(np.mean(precisions_scores) * 100, 2)\n",
    "average_f1 = round(np.mean(f1_scores) * 100, 2)\n",
    "average_accuracy = round(np.mean(accuracies_scores) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa4602ab-2c62-468e-8ecc-7dc3c93acb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.26"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d77705b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for features in x_test:\n",
    "    features = features.reshape(1, -1)\n",
    "    value = softmax.predict(features)[0]\n",
    "    y_predict.append(value)\n",
    "\n",
    "classification = classification_report(y_test, y_predict)\n",
    "confusion = confusion_matrix(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d32b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result = {'F1-score': average_f1, 'Accuracy': average_accuracy, 'Recall': average_recall, \n",
    "                 'Precision': average_precision, 'Classification Report\\n': classification, \n",
    "                 'Confusion Matrix\\n': confusion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "892ae3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score 80.24\n",
      "Accuracy 80.29\n",
      "Recall 80.26\n",
      "Precision 80.36\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.35      0.69      0.46       219\n",
      "         NEU       0.46      0.19      0.27       219\n",
      "        NONE       0.40      0.16      0.23       219\n",
      "           P       0.40      0.47      0.43       219\n",
      "\n",
      "    accuracy                           0.38       876\n",
      "   macro avg       0.40      0.38      0.35       876\n",
      "weighted avg       0.40      0.38      0.35       876\n",
      "\n",
      "Confusion Matrix\n",
      " [[151  92 118  76]\n",
      " [ 15  41  21  12]\n",
      " [ 14  12  36  27]\n",
      " [ 39  74  44 104]]\n"
     ]
    }
   ],
   "source": [
    "for item, val in output_result.items():\n",
    "    print('{0} {1}'.format(item, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b77e3b-175d-46bc-994e-41cba8840bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
